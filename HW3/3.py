# -*- coding: utf-8 -*-
"""3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e5eidu5Rkuiv_0sVludIcNu0YAYDqu5A
"""

from google.colab import drive
drive.mount('/content/drive/')

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error

data1 = np.genfromtxt('drive/My Drive/CS 498 AML/HW3/Data/dataI.csv', skip_header = 1, delimiter=",")
data2 = np.genfromtxt('drive/My Drive/CS 498 AML/HW3/Data/dataII.csv', skip_header = 1, delimiter=",")
data3 = np.genfromtxt('drive/My Drive/CS 498 AML/HW3/Data/dataIII.csv', skip_header = 1, delimiter=",")
data4 = np.genfromtxt('drive/My Drive/CS 498 AML/HW3/Data/dataIV.csv', skip_header = 1, delimiter=",")
data5 = np.genfromtxt('drive/My Drive/CS 498 AML/HW3/Data/dataV.csv', skip_header = 1, delimiter=",")
data0 = np.genfromtxt('drive/My Drive/CS 498 AML/HW3/Data/iris.csv', skip_header = 1, delimiter=",")

# Returns MSE
def MSE(x, p):
  mse = mean_squared_error(x, p, multioutput='raw_values').sum()
  return mse

# Returns matrix after PCA
def applyPCA(model, target, n_comp):
  # Number of PC
  pca = PCA(n_components = n_comp)

  # Train PCA model
  mod = pca.fit(model)

  # Apply transformation to target dataset
  recon = mod.transform(target)

  # Project back to original space
  toOrig = mod.inverse_transform(recon)
  return toOrig

# Switcher
def target(i):
  if i == 0:
    return data1
  elif i == 1:
    return data2
  elif i == 2:
    return data3
  elif i == 3:
    return data4
  else:
    return data5

results = np.zeros([5,10])

# 5 datasets
for i in range(5):
  tar = target(i)
  
#   Base model on either noisy or noiseless dataset
  for j in range(2):
    
#     Base model on noisy dataset
    if j == 1:
      for k in range(5):
        model = tar.copy()
        toOrig = applyPCA(model, tar, k)
        results[i,j*5+k] = MSE(toOrig, data0)

#     Base model on noiseless dataset
    else:
      for k in range(5):
        model = data0.copy()
        toOrig = applyPCA(model, tar, k)
        results[i,j+k] = MSE(toOrig, data0)

headr = ['0N', '1N', '2N', '3N', '4N', '0c', '1c', '2c', '3c', '4c']
df = pd.DataFrame(results, columns=headr)
df.to_csv('drive/My Drive/CS 498 AML/HW3/setwipa2-numbers.csv',index=False)

# Create and export reconstructed DataI.csv
toOrig = applyPCA(data1, data1, 2)

features = ["Sepal.Length","Sepal.Width","Petal.Length","Petal.Width"]
df = pd.DataFrame(toOrig, columns=features)
df.to_csv('drive/My Drive/CS 498 AML/HW3/setwipa2-recon.csv',index=False)