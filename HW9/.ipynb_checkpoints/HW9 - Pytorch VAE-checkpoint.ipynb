{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS498AML-HW9\n",
    "\n",
    "## About\n",
    "### Due\n",
    "Wednesday 4/24/19, 11:59 PM CST\n",
    "\n",
    "### Goal\n",
    "This homework focuses on evaluating variational autoencoders applied to the MNIST dataset.\n",
    "\n",
    "### Submission\n",
    "Submission will be through gradescope.\n",
    "\n",
    "### Code and External Libraries\n",
    "The assignment involves PyTorch, so it must be done using Python only.\n",
    "\n",
    "You may use any third-party code for the variational autoencoder. But for the rest part of the assignment, you are expected to write your own code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "#### Total points: 100\n",
    "An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. Variational autoencoder (VAE) models inherit the autoencoder architecture, but make strong assumptions concerning the distribution of latent variables. You can use this post as a reference.\n",
    "\n",
    "You have two options for this assignment:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement your own VAE. Download the Python Notebook here. Alternatively, you can access a read-only version on colab here of which you will need to make a copy. There are cells for you to input code, as well as text. Make sure to fill in all such cells before submission. Important information and sections are in bold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtain a PyTorch code for a VAE from any resource, like the example in this blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/home/cpbotha/Downloads/pytorch-vae'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dee915b31efc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# I do this so that the MNIST dataset is downloaded where I want it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/home/cpbotha/Downloads/pytorch-vae\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/home/cpbotha/Downloads/pytorch-vae'"
     ]
    }
   ],
   "source": [
    "# example from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# commented and type annotated by Charl Botha <cpbotha@vxlabs.com>\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# changed configuration to this instead of argparse for easier interaction\n",
    "CUDA = True\n",
    "SEED = 1\n",
    "BATCH_SIZE = 128\n",
    "LOG_INTERVAL = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "# connections through the autoencoder bottleneck\n",
    "# in the pytorch VAE example, this is 20\n",
    "ZDIMS = 20\n",
    "\n",
    "# I do this so that the MNIST dataset is downloaded where I want it\n",
    "os.chdir(\"/home/cpbotha/Downloads/pytorch-vae\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# DataLoader instances will load tensors directly into GPU memory\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "# Download or load downloaded MNIST dataset\n",
    "# shuffle data at every epoch\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "# Same for test data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # ENCODER\n",
    "        # 28 x 28 pixels = 784 input pixels, 400 outputs\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        # rectified linear unit layer from 400 to 400\n",
    "        # max(0, x)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc21 = nn.Linear(400, ZDIMS)  # mu layer\n",
    "        self.fc22 = nn.Linear(400, ZDIMS)  # logvariance layer\n",
    "        # this last layer bottlenecks through ZDIMS connections\n",
    "\n",
    "        # DECODER\n",
    "        # from bottleneck to hidden 400\n",
    "        self.fc3 = nn.Linear(ZDIMS, 400)\n",
    "        # from hidden 400 to 784 outputs\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x: Variable) -> (Variable, Variable):\n",
    "        \"\"\"Input vector x -> fully connected 1 -> ReLU -> (fully connected\n",
    "        21, fully connected 22)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : [128, 784] matrix; 128 digits of 28x28 pixels each\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        (mu, logvar) : ZDIMS mean units one for each latent dimension, ZDIMS\n",
    "            variance units one for each latent dimension\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # h1 is [128, 400]\n",
    "        h1 = self.relu(self.fc1(x))  # type: Variable\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu: Variable, logvar: Variable) -> Variable:\n",
    "        \"\"\"THE REPARAMETERIZATION IDEA:\n",
    "\n",
    "        For each training sample (we get 128 batched at a time)\n",
    "\n",
    "        - take the current learned mu, stddev for each of the ZDIMS\n",
    "          dimensions and draw a random sample from that distribution\n",
    "        - the whole network is trained so that these randomly drawn\n",
    "          samples decode to output that looks like the input\n",
    "        - which will mean that the std, mu will be learned\n",
    "          *distributions* that correctly encode the inputs\n",
    "        - due to the additional KLD term (see loss_function() below)\n",
    "          the distribution will tend to unit Gaussians\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : [128, ZDIMS] mean matrix\n",
    "        logvar : [128, ZDIMS] variance matrix\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        During training random sample from the learned ZDIMS-dimensional\n",
    "        normal distribution; during inference its mean.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.training:\n",
    "            # multiply log variance with 0.5, then in-place exponent\n",
    "            # yielding the standard deviation\n",
    "            std = logvar.mul(0.5).exp_()  # type: Variable\n",
    "            # - std.data is the [128,ZDIMS] tensor that is wrapped by std\n",
    "            # - so eps is [128,ZDIMS] with all elements drawn from a mean 0\n",
    "            #   and stddev 1 normal distribution that is 128 samples\n",
    "            #   of random ZDIMS-float vectors\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            # - sample from a normal distribution with standard\n",
    "            #   deviation = std and mean = mu by multiplying mean 0\n",
    "            #   stddev 1 sample with desired std and mu, see\n",
    "            #   https://stats.stackexchange.com/a/16338\n",
    "            # - so we have 128 sets (the batch) of random ZDIMS-float\n",
    "            #   vectors sampled from normal distribution with learned\n",
    "            #   std and mu for the current input\n",
    "            return eps.mul(std).add_(mu)\n",
    "\n",
    "        else:\n",
    "            # During inference, we simply spit out the mean of the\n",
    "            # learned distribution for the current input.  We could\n",
    "            # use a random sample from the distribution, but mu of\n",
    "            # course has the highest probability.\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z: Variable) -> Variable:\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x: Variable) -> (Variable, Variable, Variable):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar) -> Variable:\n",
    "    # how well do input x and output recon_x agree?\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784))\n",
    "\n",
    "    # KLD is Kullbackâ€“Leibler divergence -- how much does one learned\n",
    "    # distribution deviate from another, in this specific case the\n",
    "    # learned distribution from the unit Gaussian\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # - D_{KL} = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # note the negative D_{KL} in appendix B of the paper\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Normalise by same number of elements as in reconstruction\n",
    "    KLD /= BATCH_SIZE * 784\n",
    "\n",
    "    # BCE tries to make our reconstruction as accurate as possible\n",
    "    # KLD tries to push the distributions as close as possible to unit Gaussian\n",
    "    return BCE + KLD\n",
    "\n",
    "# Dr Diederik Kingma: as if VAEs weren't enough, he also gave us Adam!\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    # toggle model to train mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # in the case of MNIST, len(train_loader.dataset) is 60000\n",
    "    # each `data` is of BATCH_SIZE samples and has shape [128, 1, 28, 28]\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # push whole batch of data through VAE.forward() to get recon_loss\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        # calculate scalar loss\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        # calculate the gradient of the loss w.r.t. the graph leaves\n",
    "        # i.e. input variables -- by the power of pytorch!\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    # toggle model to test / inference mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # each data is of BATCH_SIZE (default 128) samples\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        if CUDA:\n",
    "            # make sure this lives on the GPU\n",
    "            data = data.cuda()\n",
    "\n",
    "        # we're only going to infer, so no autograd at all required: volatile=True\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "        if i == 0:\n",
    "          n = min(data.size(0), 8)\n",
    "          # for the first 128 batch of the epoch, show the first 8 input digits\n",
    "          # with right below them the reconstructed output digits\n",
    "          comparison = torch.cat([data[:n],\n",
    "                                  recon_batch.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "          save_image(comparison.data.cpu(),\n",
    "                     'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    # 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\n",
    "    # digits in latent space\n",
    "    sample = Variable(torch.randn(64, ZDIMS))\n",
    "    if CUDA:\n",
    "        sample = sample.cuda()\n",
    "    sample = model.decode(sample).cpu()\n",
    "\n",
    "    # save out as an 8x8 matrix of MNIST digits\n",
    "    # this will give you a visual idea of how well latent space can generate things\n",
    "    # that look like digits\n",
    "    save_image(sample.data.view(64, 1, 28, 28),\n",
    "               'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train this autoencoder on the MNIST dataset. Use only the MNIST training set for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now determine how well the codes produced by this autoencoder can be interpolated. Use only the MNIST test set for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For 10 pairs of MNIST test images of the same digit (1 pair for \"0\", 1 pair for \"1\", etc.), selected at random, compute the code for each image of the pair. Now compute 7 evenly spaced linear interpolates between these codes, and decode the result into images. Prepare a figure showing this interpolate. Lay out the figure so each interpolate is a row. On the left of the row is the first test image; then the interpolate closest to it; etc; to the last test image. You should have a 10 rows (1 row per digit) and 9 columns (7 interpolates + 2 selected test images) of images. You should give a figure like (make yours bigger):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For 10 pairs of MNIST test images of different digits selected at random, compute the code for each image of the pair. Now compute 7 evenly spaced linear interpolates between these codes, and decode the result into images. Prepare a figure showing this interpolate. Lay out the figure so each interpolate is a row. On the left of the row is the first test image; then the interpolate closest to it; etc; to the last test image. You should have a 10 rows and 9 columns of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
